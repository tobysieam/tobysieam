## 1. 准备（环境与依赖）
1. 请确保已安装 Python 3.8+。在 PowerShell 中检查：
```powershell
python --version
```

2. （可选）安装测试与绘图依赖（建议安装，用于运行 pytest 与生成性能图）：
```powershell
python -m pip install --upgrade pip
python -m pip install pytest matplotlib
```
项目内有 `requirements.txt`（目前为空），但上面两个包是可选依赖。

3. 切换到项目目录（以你的工作区为例）：
```powershell
Set-Location e:\tobysieam\结对项目
```

## 2. 快速生成题目（生成模式）
- 命令格式：`python main.py -n <数量> -r <范围> [-o <输出目录>]`
  - `-n`：要生成的题目数量（1..10000）
  - `-r`：数值上界 r（生成的自然数与分数分母都 < r），生成模式必须指定
  - `-o` / `--out-dir`：可选，指定输出目录（默认当前工作目录）

示例（在当前目录生成 10 道、范围 10）：
```powershell
python main.py -n 10 -r 10
```

示例（把输出写到子目录 `out_test`）：
```powershell
python main.py -n 20 -r 20 -o e:/tobysieam/结对项目/out_test
```
运行后会在输出目录产生：
- Exercises.txt（题目，每行类似：`(1/2 + 3) * 2 =`）
- Answers.txt（对应答案，每行一种格式，混合数用 ASCII 单引号：`2'3/8`）

注意：程序支持一次最多 10000 道题（受机器与内存影响）。

## 3. 批改（判分模式）
- 命令格式：`python main.py -e <exercisefile> -a <answerfile> [-o <outdir>]`

示例（用项目根的 Exercises.txt 与 Answers.txt）：
```powershell
python main.py -e e:/tobysieam/Exercises.txt -a e:/tobysieam/Answers.txt
```

示例（并把 Grade.txt 写入指定目录）：
```powershell
python main.py -e e:/tobysieam/Exercises.txt -a e:/tobysieam/Answers_user.txt -o e:/tobysieam/结对项目/out_test
```
生成文件：
- Grade.txt：包含 Correct/Wrong 数量与题号列表，例如：
  ```
  Correct: 10 (1, 2, 3, ...)
  Wrong: 0 ()
  ```

## 4. 文件与格式说明（重要）
- Exercises.txt：每行是一个题目（表达式）后面跟 ` =`，例如：
  ```
  (1/2 + 3) * 2 =
  4 - 0 =
  ```
- Answers.txt：每行一个答案。格式规范：
  - 自然数：`4`
  - 真分数：`3/5`
  - 带分数：`2'3/8`（用 ASCII 单引号 `'`）
- 解析器也接受 Unicode 撇号 `’`，但输出统一为 ASCII `'`。
- 判分时假设题目按顺序编号，答案文件每行对应一道题。

## 5. 调试与辅助脚本
- 用于快速对比生成题目与答案的脚本：
  ```powershell
  python check_eval.py
  ```
  它会把每道题计算结果与 Answers.txt 做比对并在终端打印差异（方便调试）。
- 有个 `run_grade.py` 可以打印每道错题的规范化比较信息：
  ```powershell
  python run_grade.py
  ```

## 6. 性能测试与绘图
- 基线性能脚本（生成 N 道题并测时）：
  ```powershell
  python perf_test.py 1000 100
  ```
  参数：`<N> <r>`（例如 `1000 100`），会把结果追加到 report.md。

- 生成并绘制多组基线（会生成 `perf.png` 并写 final_report.md）：
  ```powershell
  python plot_perf.py
  ```
  该脚本会依次运行多组 `perf`（100,1000,5000,10000），并尝试用 matplotlib 生成 `perf.png`。若缺失 matplotlib，会在 final_report.md 中给出说明。

## 7. 运行单元测试（pytest）
- 在项目根目录运行：
```powershell
python -m pytest -q e:/tobysieam/结对项目/tests
```
或者简写（在当前目录下）：
```powershell
pytest -q
```
所有测试应通过（项目内已有多项测试覆盖解析、生成器约束、去重等）。

## 8. 快速验证流程（示例）
1. 生成 50 道题并写到 `out_test`：
```powershell
python main.py -n 50 -r 20 -o e:/tobysieam/结对项目/out_test
```
2. 用生成的 Answers.txt 判分（应该全部正确）：
```powershell
python main.py -e e:/tobysieam/结对项目/out_test/Exercises.txt -a e:/tobysieam/结对项目/out_test/Answers.txt -o e:/tobysieam/结对项目/out_test
```
3. 查看 Grade.txt：
```powershell
Get-Content e:/tobysieam/结对项目/out_test/Grade.txt
```

## 9. 常见问题与排查
- 报错 “生成模式 (-n) 必须同时指定 -r 参数”：表示你使用了 `-n` 但没有给 `-r`，请加上 `-r <范围>`。
- 判分结果显示错误但你认为答案正确：
  - 检查 Answers.txt 中带分数是否使用 ASCII `'`（程序也接受 Unicode，但 normalize 用 ASCII）。
  - 使用 `check_eval.py` 或 `run_grade.py` 查看规范化后的真实答案与用户答案。
- 若出现 ZeroDivisionError：说明输入题目有除以 0 的情况（生成器应该避免，但外部题目文件可能存在），应在题目文件中修正该题。

## 10. 如果你要提交作业（建议）
- 先运行所有测试确保通过：
```powershell
pytest -q
```
- 生成 Exercises.txt 与 Answers.txt，并用 `main.py` 判分一次以确保 Grade.txt 输出正常。
